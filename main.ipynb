{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Michael-David-Lam/NLP-Final-Project/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Libraries/Dependencies Installation"
      ],
      "metadata": {
        "id": "uTiJ5gIWRCP0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jWKCC-_gXWtc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "947415fa-f7c4-4678-cafd-5c86bc3947d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in ./anaconda3/lib/python3.11/site-packages (from seqeval) (1.26.3)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in ./anaconda3/lib/python3.11/site-packages (from seqeval) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in ./anaconda3/lib/python3.11/site-packages (from scikit-learn>=0.21.3->seqeval) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in ./anaconda3/lib/python3.11/site-packages (from scikit-learn>=0.21.3->seqeval) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in ./anaconda3/lib/python3.11/site-packages (from scikit-learn>=0.21.3->seqeval) (2.2.0)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \bdone\n",
            "\u001b[?25h  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16164 sha256=f8c06d192c4f10aaa33bb3b3e09219b34337b44f536610895574e15195570b89\n",
            "  Stored in directory: /Users/darren/Library/Caches/pip/wheels/bc/92/f0/243288f899c2eacdfa8c5f9aede4c71a9bad0ee26a01dc5ead\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-1.2.2\n",
            "Found existing installation: torch 2.4.1\n",
            "Uninstalling torch-2.4.1:\n",
            "  Successfully uninstalled torch-2.4.1\n",
            "\u001b[33mWARNING: Skipping torchtext as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting torch==2.0.1\n",
            "  Obtaining dependency information for torch==2.0.1 from https://files.pythonhosted.org/packages/85/68/f901437d3e3ef6fe97adb1f372479626d994185b8fa06803f5bdf3bb90fd/torch-2.0.1-cp311-none-macosx_11_0_arm64.whl.metadata\n",
            "  Downloading torch-2.0.1-cp311-none-macosx_11_0_arm64.whl.metadata (23 kB)\n",
            "Collecting torchtext==0.15.2\n",
            "  Obtaining dependency information for torchtext==0.15.2 from https://files.pythonhosted.org/packages/59/e9/1d3ecd04ef057277ba7e3ad0b8793f0d161b60a4ba7fe0b9aa6870a498e4/torchtext-0.15.2-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
            "  Downloading torchtext-0.15.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: filelock in ./anaconda3/lib/python3.11/site-packages (from torch==2.0.1) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in ./anaconda3/lib/python3.11/site-packages (from torch==2.0.1) (4.9.0)\n",
            "Requirement already satisfied: sympy in ./anaconda3/lib/python3.11/site-packages (from torch==2.0.1) (1.12)\n",
            "Requirement already satisfied: networkx in ./anaconda3/lib/python3.11/site-packages (from torch==2.0.1) (3.1)\n",
            "Requirement already satisfied: jinja2 in ./anaconda3/lib/python3.11/site-packages (from torch==2.0.1) (3.1.2)\n",
            "Requirement already satisfied: tqdm in ./anaconda3/lib/python3.11/site-packages (from torchtext==0.15.2) (4.67.1)\n",
            "Requirement already satisfied: requests in ./anaconda3/lib/python3.11/site-packages (from torchtext==0.15.2) (2.32.3)\n",
            "Requirement already satisfied: numpy in ./anaconda3/lib/python3.11/site-packages (from torchtext==0.15.2) (1.26.3)\n",
            "Collecting torchdata==0.6.1 (from torchtext==0.15.2)\n",
            "  Obtaining dependency information for torchdata==0.6.1 from https://files.pythonhosted.org/packages/13/53/55bf15592605643e9ab1e612814ddd360f008b78142eb5782b12be63389a/torchdata-0.6.1-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
            "  Downloading torchdata-0.6.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: urllib3>=1.25 in ./anaconda3/lib/python3.11/site-packages (from torchdata==0.6.1->torchtext==0.15.2) (1.26.18)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in ./anaconda3/lib/python3.11/site-packages (from jinja2->torch==2.0.1) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./anaconda3/lib/python3.11/site-packages (from requests->torchtext==0.15.2) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./anaconda3/lib/python3.11/site-packages (from requests->torchtext==0.15.2) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./anaconda3/lib/python3.11/site-packages (from requests->torchtext==0.15.2) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in ./anaconda3/lib/python3.11/site-packages (from sympy->torch==2.0.1) (1.3.0)\n",
            "Downloading torch-2.0.1-cp311-none-macosx_11_0_arm64.whl (55.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchtext-0.15.2-cp311-cp311-macosx_11_0_arm64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchdata-0.6.1-cp311-cp311-macosx_11_0_arm64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch, torchdata, torchtext\n",
            "Successfully installed torch-2.0.1 torchdata-0.6.1 torchtext-0.15.2\n"
          ]
        }
      ],
      "source": [
        "# !pip install datasets\n",
        "# !pip install gensim\n",
        "# !pip install --upgrade numpy gensim\n",
        "# !pip install tensorflow\n",
        "# !pip install seqeval\n",
        "# !pip uninstall -y torch torchtext\n",
        "# !pip install torch==2.0.1 torchtext==0.15.2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup 1 (Word2Vec)"
      ],
      "metadata": {
        "id": "Uui459BGO23m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "from gensim.models import Word2Vec\n",
        "import ast\n",
        "from gensim.models import KeyedVectors\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, Bidirectional, LSTM, TimeDistributed, Dense, Masking\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from seqeval.metrics import classification_report, f1_score"
      ],
      "metadata": {
        "id": "06GTRetkG1bS"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"surrey-nlp/PLOD-CW-25\")\n",
        "print(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUG9YpxlDAIJ",
        "outputId": "641835f6-57e1-4d12-e58c-40bb63fdb7f8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['tokens', 'pos_tags', 'ner_tags'],\n",
            "        num_rows: 2000\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['tokens', 'pos_tags', 'ner_tags'],\n",
            "        num_rows: 250\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['tokens', 'pos_tags', 'ner_tags'],\n",
            "        num_rows: 150\n",
            "    })\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.DataFrame(dataset[\"train\"])\n",
        "df_val = pd.DataFrame(dataset[\"validation\"])\n",
        "df_test = pd.DataFrame(dataset[\"test\"])"
      ],
      "metadata": {
        "id": "PvGTSh7QGtXH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#To combine train,test,split for vectorisation to build a rich embedding space\n",
        "\n",
        "import ast\n",
        "\n",
        "def safe_parse(col):\n",
        "    return [ast.literal_eval(row) if isinstance(row, str) else row for row in col]\n",
        "\n",
        "train_tokens = safe_parse(df_train[\"tokens\"])\n",
        "val_tokens = safe_parse(df_val[\"tokens\"])\n",
        "test_tokens = safe_parse(df_test[\"tokens\"])\n",
        "\n",
        "all_tokens = train_tokens + val_tokens + test_tokens"
      ],
      "metadata": {
        "id": "bWoGJ6j2Ngdh"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#List of Parameters (Just using Lab as reference)\n",
        "num_features = 300\n",
        "min_word_count = 1\n",
        "num_workers = 2\n",
        "window_size = 3\n",
        "subsampling = 1e-3"
      ],
      "metadata": {
        "id": "szJampFkSKhQ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model = Word2Vec(\n",
        "    sentences=all_tokens,\n",
        "    vector_size=num_features,\n",
        "    window=window_size,\n",
        "    min_count=min_word_count,\n",
        "    workers=num_workers,\n",
        "    sample=subsampling\n",
        ")"
      ],
      "metadata": {
        "id": "POZaiqLzSNRn"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = w2v_model.wv.index_to_key\n",
        "word_index = {word: idx + 1 for idx, word in enumerate(vocab)}\n",
        "\n",
        "embedding_dim = w2v_model.vector_size\n",
        "embedding_matrix = np.zeros((len(word_index) + 1, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    embedding_matrix[i] = w2v_model.wv[word]"
      ],
      "metadata": {
        "id": "BoE-4X22RaGk"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_lengths = [len(seq) for seq in train_tokens + val_tokens + test_tokens]\n",
        "\n",
        "print(max(all_lengths))\n",
        "print(np.mean(all_lengths))\n",
        "print(np.percentile(all_lengths, 90))\n",
        "#likelihood to chose 76 to get the best balance of computational power + covers 90% of sequence"
      ],
      "metadata": {
        "id": "nHg88SqASwnu",
        "outputId": "3d0f8afd-5a53-48ca-c007-ec9c64516ace",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "371\n",
            "41.17041666666667\n",
            "76.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode as Bi-LSTM requires numbers to process\n",
        "\n",
        "def encode_sentences(token_lists, word_index, max_len):\n",
        "    sequences = [[word_index.get(token, 0) for token in tokens] for tokens in token_lists]\n",
        "    return pad_sequences(sequences, maxlen=max_len, padding=\"post\", truncating=\"post\")\n",
        "\n",
        "#using 90th percentile first\n",
        "max_len = 76\n",
        "\n",
        "X_train = encode_sentences(train_tokens, word_index, max_len)\n",
        "X_val = encode_sentences(val_tokens, word_index, max_len)\n",
        "X_test = encode_sentences(test_tokens, word_index, max_len)"
      ],
      "metadata": {
        "id": "Yj8hDcfLTdVX"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_tags = df_train[\"ner_tags\"].tolist() + df_val[\"ner_tags\"].tolist() + df_test[\"ner_tags\"].tolist()\n",
        "\n",
        "tag_encoder = LabelEncoder()\n",
        "tag_encoder.fit([tag for seq in all_tags for tag in seq])\n",
        "num_classes = len(tag_encoder.classes_)\n",
        "\n",
        "def encode_tags(tag_lists, max_len):\n",
        "    encoded = [tag_encoder.transform(tags) for tags in tag_lists]\n",
        "    padded = pad_sequences(encoded, maxlen=max_len, padding=\"post\", truncating=\"post\", value=-1)  # -1 for masking\n",
        "    return padded\n",
        "\n",
        "y_train = encode_tags(df_train[\"ner_tags\"].tolist(), max_len)\n",
        "y_val = encode_tags(df_val[\"ner_tags\"].tolist(), max_len)\n",
        "y_test = encode_tags(df_test[\"ner_tags\"].tolist(), max_len)"
      ],
      "metadata": {
        "id": "JsH1nvzeTi1W"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = Input(shape=(max_len,))\n",
        "model = Embedding(input_dim=embedding_matrix.shape[0],\n",
        "                  output_dim=embedding_matrix.shape[1],\n",
        "                  weights=[embedding_matrix],\n",
        "                  input_length=max_len,\n",
        "                  mask_zero=True,\n",
        "                  trainable=True)(input)\n",
        "model = Bidirectional(LSTM(units=128, return_sequences=True))(model)\n",
        "model = Dense(num_classes, activation=\"softmax\")(model)\n",
        "\n",
        "model = Model(input, model)\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "yQdk7gF5TqX3",
        "outputId": "09f6615c-e1aa-49e2-ecf9-b8be4336e863",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/Users/darren/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m76\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m76\u001b[0m, \u001b[38;5;34m300\u001b[0m)   │  \u001b[38;5;34m4,947,600\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ not_equal           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m76\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m76\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │    \u001b[38;5;34m439,296\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │ not_equal[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m76\u001b[0m, \u001b[38;5;34m4\u001b[0m)     │      \u001b[38;5;34m1,028\u001b[0m │ bidirectional[\u001b[38;5;34m0\u001b[0m]… │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">76</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">76</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">4,947,600</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ not_equal           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">76</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">76</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">439,296</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │ not_equal[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">76</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,028</span> │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,387,924\u001b[0m (20.55 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,387,924</span> (20.55 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,387,924\u001b[0m (20.55 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,387,924</span> (20.55 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_sample_weights(y_padded):\n",
        "    return (y_padded != -1).astype(\"float32\")\n",
        "\n",
        "sample_weights_train = create_sample_weights(y_train)\n",
        "sample_weights_val = create_sample_weights(y_val)\n",
        "\n",
        "y_train = np.where(y_train == -1, 0, y_train)\n",
        "y_val = np.where(y_val == -1, 0, y_val)"
      ],
      "metadata": {
        "id": "iOnwb92DT0_V"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training of model (using Adam as a baseline optimiser)\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.001),\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train[..., np.newaxis],\n",
        "    validation_data=(X_val, y_val[..., np.newaxis], sample_weights_val),\n",
        "    sample_weight=sample_weights_train,\n",
        "    batch_size=32,\n",
        "    epochs=15\n",
        ")"
      ],
      "metadata": {
        "id": "_sv64A07T3g-",
        "outputId": "8dc414ec-ab4f-402f-8b78-49ce776e7756",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 97ms/step - accuracy: 0.3948 - loss: 0.8025 - val_accuracy: 0.4146 - val_loss: 0.4808\n",
            "Epoch 2/15\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 123ms/step - accuracy: 0.4284 - loss: 0.4060 - val_accuracy: 0.4308 - val_loss: 0.3727\n",
            "Epoch 3/15\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 159ms/step - accuracy: 0.4634 - loss: 0.2556 - val_accuracy: 0.4327 - val_loss: 0.3624\n",
            "Epoch 4/15\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 157ms/step - accuracy: 0.4774 - loss: 0.1397 - val_accuracy: 0.4305 - val_loss: 0.3811\n",
            "Epoch 5/15\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 151ms/step - accuracy: 0.4813 - loss: 0.0830 - val_accuracy: 0.4335 - val_loss: 0.4154\n",
            "Epoch 6/15\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 148ms/step - accuracy: 0.4888 - loss: 0.0611 - val_accuracy: 0.4288 - val_loss: 0.4523\n",
            "Epoch 7/15\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 155ms/step - accuracy: 0.4911 - loss: 0.0372 - val_accuracy: 0.4314 - val_loss: 0.4714\n",
            "Epoch 8/15\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 157ms/step - accuracy: 0.4858 - loss: 0.0299 - val_accuracy: 0.4310 - val_loss: 0.4846\n",
            "Epoch 9/15\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 163ms/step - accuracy: 0.5133 - loss: 0.0206 - val_accuracy: 0.4291 - val_loss: 0.5254\n",
            "Epoch 10/15\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 164ms/step - accuracy: 0.5053 - loss: 0.0126 - val_accuracy: 0.4299 - val_loss: 0.5354\n",
            "Epoch 11/15\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 163ms/step - accuracy: 0.5027 - loss: 0.0102 - val_accuracy: 0.4262 - val_loss: 0.6029\n",
            "Epoch 12/15\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 161ms/step - accuracy: 0.5031 - loss: 0.0085 - val_accuracy: 0.4282 - val_loss: 0.5859\n",
            "Epoch 13/15\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 165ms/step - accuracy: 0.4978 - loss: 0.0053 - val_accuracy: 0.4254 - val_loss: 0.6105\n",
            "Epoch 14/15\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 161ms/step - accuracy: 0.4917 - loss: 0.0037 - val_accuracy: 0.4296 - val_loss: 0.6186\n",
            "Epoch 15/15\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 172ms/step - accuracy: 0.5027 - loss: 0.0032 - val_accuracy: 0.4273 - val_loss: 0.6450\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_pred_labels = np.argmax(y_pred, axis=-1)\n",
        "\n",
        "idx2tag = {i: t for i, t in enumerate(tag_encoder.classes_)}\n",
        "\n",
        "true_labels = [[idx2tag[idx] for idx in row if idx != -1] for row in y_test]\n",
        "pred_labels = [[idx2tag[idx] for idx in row[:len(true_labels[i])]] for i, row in enumerate(y_pred_labels)]\n",
        "\n",
        "print(\"F1 Score:\", f1_score(true_labels, pred_labels))\n",
        "print(classification_report(true_labels, pred_labels))"
      ],
      "metadata": {
        "id": "B5s8ak6yT5wO",
        "outputId": "2bdf509f-571d-4992-cc62-df8cfbfdfa24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "F1 Score: 0.6510263929618768\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          AC       0.77      0.72      0.74       741\n",
            "          LF       0.49      0.54      0.52       455\n",
            "\n",
            "   micro avg       0.65      0.65      0.65      1196\n",
            "   macro avg       0.63      0.63      0.63      1196\n",
            "weighted avg       0.66      0.65      0.66      1196\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set up 2 (Glove)"
      ],
      "metadata": {
        "id": "L4-I8pHaZDIb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"surrey-nlp/PLOD-CW-25\")\n",
        "\n",
        "print(dataset)"
      ],
      "metadata": {
        "id": "5Sc7g6RKZVVO",
        "outputId": "38865f67-91bd-495a-f64e-9a8e49ef845b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['tokens', 'pos_tags', 'ner_tags'],\n",
            "        num_rows: 2000\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['tokens', 'pos_tags', 'ner_tags'],\n",
            "        num_rows: 250\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['tokens', 'pos_tags', 'ner_tags'],\n",
            "        num_rows: 150\n",
            "    })\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.DataFrame(dataset[\"train\"])\n",
        "df_val = pd.DataFrame(dataset[\"validation\"])\n",
        "df_test = pd.DataFrame(dataset[\"test\"])"
      ],
      "metadata": {
        "id": "3KS-HpK2bRUl"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def safe_parse(col):\n",
        "    return [ast.literal_eval(row) if isinstance(row, str) else row for row in col]\n",
        "\n",
        "train_tokens = safe_parse(df_train[\"tokens\"])\n",
        "val_tokens = safe_parse(df_val[\"tokens\"])\n",
        "test_tokens = safe_parse(df_test[\"tokens\"])\n",
        "\n",
        "all_tokens = train_tokens + val_tokens + test_tokens"
      ],
      "metadata": {
        "id": "4gv4YxfQbTpg"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.vocab import GloVe\n",
        "\n",
        "\n",
        "glove = GloVe(name='6B', dim=300)"
      ],
      "metadata": {
        "id": "2I9oq2OhbWPX"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = set(token for sentence in train_tokens + val_tokens + test_tokens for token in sentence)\n",
        "word_index = {word: i + 1 for i, word in enumerate(vocab)}\n",
        "\n",
        "embedding_dim = 300\n",
        "embedding_matrix = np.zeros((len(word_index) + 1, embedding_dim))\n",
        "\n",
        "for word, i in word_index.items():\n",
        "    if word in glove.stoi:\n",
        "        embedding_matrix[i] = glove[word].numpy()"
      ],
      "metadata": {
        "id": "bQqmAS4FbY-Q"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_layer = Embedding(\n",
        "    input_dim=embedding_matrix.shape[0],\n",
        "    output_dim=embedding_dim,\n",
        "    weights=[embedding_matrix],\n",
        "    mask_zero=True,\n",
        "    trainable=True\n",
        ")"
      ],
      "metadata": {
        "id": "C9qtpJGBbb_7"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_sentences(token_lists, word_index, max_len):\n",
        "    sequences = [[word_index.get(token, 0) for token in tokens] for tokens in token_lists]\n",
        "    return pad_sequences(sequences, maxlen=max_len, padding=\"post\", truncating=\"post\")\n",
        "\n",
        "#using 90th percentile first\n",
        "max_len = 76\n",
        "\n",
        "X_train = encode_sentences(train_tokens, word_index, max_len)\n",
        "X_val = encode_sentences(val_tokens, word_index, max_len)\n",
        "X_test = encode_sentences(test_tokens, word_index, max_len)"
      ],
      "metadata": {
        "id": "7bpPDokibfhl"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_tags = df_train[\"ner_tags\"].tolist() + df_val[\"ner_tags\"].tolist() + df_test[\"ner_tags\"].tolist()\n",
        "\n",
        "tag_encoder = LabelEncoder()\n",
        "tag_encoder.fit([tag for seq in all_tags for tag in seq])\n",
        "num_classes = len(tag_encoder.classes_)\n",
        "\n",
        "def encode_tags(tag_lists, max_len):\n",
        "    encoded = [tag_encoder.transform(tags) for tags in tag_lists]\n",
        "    padded = pad_sequences(encoded, maxlen=max_len, padding=\"post\", truncating=\"post\", value=-1)  # -1 for masking\n",
        "    return padded\n",
        "\n",
        "y_train = encode_tags(df_train[\"ner_tags\"].tolist(), max_len)\n",
        "y_val = encode_tags(df_val[\"ner_tags\"].tolist(), max_len)\n",
        "y_test = encode_tags(df_test[\"ner_tags\"].tolist(), max_len)"
      ],
      "metadata": {
        "id": "R-55htcMbhpR"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = Input(shape=(max_len,))\n",
        "model = Embedding(input_dim=embedding_matrix.shape[0],\n",
        "                  output_dim=embedding_matrix.shape[1],\n",
        "                  weights=[embedding_matrix],\n",
        "                  input_length=max_len,\n",
        "                  mask_zero=True,\n",
        "                  trainable=True)(input)\n",
        "model = Bidirectional(LSTM(units=128, return_sequences=True))(model)\n",
        "model = Dense(num_classes, activation=\"softmax\")(model)\n",
        "\n",
        "model = Model(input, model)\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "Xyym4hBTbkqt",
        "outputId": "c0b96d7e-79b4-486b-af12-8f8aebd5bb75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/Users/darren/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_3       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m76\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_6         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m76\u001b[0m, \u001b[38;5;34m300\u001b[0m)   │  \u001b[38;5;34m4,947,600\u001b[0m │ input_layer_3[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ not_equal_3         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m76\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ input_layer_3[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_3     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m76\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │    \u001b[38;5;34m439,296\u001b[0m │ embedding_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │ not_equal_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m76\u001b[0m, \u001b[38;5;34m4\u001b[0m)     │      \u001b[38;5;34m1,028\u001b[0m │ bidirectional_3[\u001b[38;5;34m…\u001b[0m │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_3       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">76</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_6         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">76</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">4,947,600</span> │ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ not_equal_3         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">76</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_3     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">76</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">439,296</span> │ embedding_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │ not_equal_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">76</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,028</span> │ bidirectional_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,387,924\u001b[0m (20.55 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,387,924</span> (20.55 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,387,924\u001b[0m (20.55 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,387,924</span> (20.55 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_sample_weights(y_padded):\n",
        "    return (y_padded != -1).astype(\"float32\")\n",
        "\n",
        "sample_weights_train = create_sample_weights(y_train)\n",
        "sample_weights_val = create_sample_weights(y_val)\n",
        "\n",
        "y_train = np.where(y_train == -1, 0, y_train)\n",
        "y_val = np.where(y_val == -1, 0, y_val)"
      ],
      "metadata": {
        "id": "UkdfcgnEbouA"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.001),\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train[..., np.newaxis],\n",
        "    validation_data=(X_val, y_val[..., np.newaxis], sample_weights_val),\n",
        "    sample_weight=sample_weights_train,\n",
        "    batch_size=32,\n",
        "    epochs=15\n",
        ")"
      ],
      "metadata": {
        "id": "fPhOuFnPbp9R",
        "outputId": "daf2070e-0028-4237-948a-0eaa21c344f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 97ms/step - accuracy: 0.4035 - loss: 0.7295 - val_accuracy: 0.4181 - val_loss: 0.4146\n",
            "Epoch 2/15\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 130ms/step - accuracy: 0.4274 - loss: 0.3437 - val_accuracy: 0.4316 - val_loss: 0.3494\n",
            "Epoch 3/15\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 160ms/step - accuracy: 0.4449 - loss: 0.2370 - val_accuracy: 0.4330 - val_loss: 0.3323\n",
            "Epoch 4/15\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 165ms/step - accuracy: 0.4740 - loss: 0.1512 - val_accuracy: 0.4358 - val_loss: 0.3489\n",
            "Epoch 5/15\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 156ms/step - accuracy: 0.4832 - loss: 0.0943 - val_accuracy: 0.4329 - val_loss: 0.3727\n",
            "Epoch 6/15\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 161ms/step - accuracy: 0.4928 - loss: 0.0627 - val_accuracy: 0.4330 - val_loss: 0.4156\n",
            "Epoch 7/15\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 159ms/step - accuracy: 0.4955 - loss: 0.0379 - val_accuracy: 0.4344 - val_loss: 0.4255\n",
            "Epoch 8/15\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 159ms/step - accuracy: 0.5032 - loss: 0.0243 - val_accuracy: 0.4336 - val_loss: 0.4626\n",
            "Epoch 9/15\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 160ms/step - accuracy: 0.5039 - loss: 0.0182 - val_accuracy: 0.4321 - val_loss: 0.5011\n",
            "Epoch 10/15\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 162ms/step - accuracy: 0.5011 - loss: 0.0122 - val_accuracy: 0.4326 - val_loss: 0.5116\n",
            "Epoch 11/15\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 167ms/step - accuracy: 0.4998 - loss: 0.0089 - val_accuracy: 0.4318 - val_loss: 0.5356\n",
            "Epoch 12/15\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 173ms/step - accuracy: 0.4947 - loss: 0.0078 - val_accuracy: 0.4324 - val_loss: 0.5610\n",
            "Epoch 13/15\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 170ms/step - accuracy: 0.5007 - loss: 0.0053 - val_accuracy: 0.4314 - val_loss: 0.5872\n",
            "Epoch 14/15\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 167ms/step - accuracy: 0.5038 - loss: 0.0032 - val_accuracy: 0.4331 - val_loss: 0.5920\n",
            "Epoch 15/15\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 166ms/step - accuracy: 0.5029 - loss: 0.0030 - val_accuracy: 0.4326 - val_loss: 0.6194\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_pred_labels = np.argmax(y_pred, axis=-1)\n",
        "\n",
        "idx2tag = {i: t for i, t in enumerate(tag_encoder.classes_)}\n",
        "\n",
        "true_labels = [[idx2tag[idx] for idx in row if idx != -1] for row in y_test]\n",
        "pred_labels = [[idx2tag[idx] for idx in row[:len(true_labels[i])]] for i, row in enumerate(y_pred_labels)]\n",
        "\n",
        "print(\"F1 Score:\", f1_score(true_labels, pred_labels))\n",
        "print(classification_report(true_labels, pred_labels))"
      ],
      "metadata": {
        "id": "LW5olq9qbp-l",
        "outputId": "e34fcbe0-1f30-459f-9b89-99554a67a73b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:5 out of the last 17 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x32a190fe0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "F1 Score: 0.6914285714285714\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          AC       0.78      0.76      0.77       741\n",
            "          LF       0.53      0.62      0.57       455\n",
            "\n",
            "   micro avg       0.68      0.71      0.69      1196\n",
            "   macro avg       0.66      0.69      0.67      1196\n",
            "weighted avg       0.69      0.71      0.70      1196\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set up 3 (Fast Text)"
      ],
      "metadata": {
        "id": "pt_7XdHnYiBE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.vocab import FastText\n",
        "\n",
        "fasttext = FastText(language='en')"
      ],
      "metadata": {
        "id": "UKaTDzcpIF8U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d0d50e7-2889-46e0-8492-2d2e4259fad9"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ".vector_cache/wiki.en.vec: 6.60GB [12:36, 8.72MB/s]\n",
            "  0%|                                               | 0/2519370 [00:00<?, ?it/s]Skipping token b'2519370' with 1-dimensional vector [b'300']; likely a header\n",
            "100%|██████████████████████████████| 2519370/2519370 [01:59<00:00, 21148.19it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"surrey-nlp/PLOD-CW-25\")\n",
        "\n",
        "print(dataset)"
      ],
      "metadata": {
        "id": "oHR2mJnVUzvW",
        "outputId": "d67d4bec-0ea2-4143-a6f5-c691f8ee058c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['tokens', 'pos_tags', 'ner_tags'],\n",
            "        num_rows: 2000\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['tokens', 'pos_tags', 'ner_tags'],\n",
            "        num_rows: 250\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['tokens', 'pos_tags', 'ner_tags'],\n",
            "        num_rows: 150\n",
            "    })\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.DataFrame(dataset[\"train\"])\n",
        "df_val = pd.DataFrame(dataset[\"validation\"])\n",
        "df_test = pd.DataFrame(dataset[\"test\"])"
      ],
      "metadata": {
        "id": "tPuzQBy0U1gZ"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#To combine train,test,split for vectorisation to build a rich embedding space\n",
        "\n",
        "def safe_parse(col):\n",
        "    return [ast.literal_eval(row) if isinstance(row, str) else row for row in col]\n",
        "\n",
        "train_tokens = safe_parse(df_train[\"tokens\"])\n",
        "val_tokens = safe_parse(df_val[\"tokens\"])\n",
        "test_tokens = safe_parse(df_test[\"tokens\"])\n",
        "\n",
        "all_tokens = train_tokens + val_tokens + test_tokens"
      ],
      "metadata": {
        "id": "FrQ2V7HGVDnH"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preparation of data (Creating vocab + embeding matrix from model itself)"
      ],
      "metadata": {
        "id": "SHmO8pSxQoOB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = set(token for sentence in train_tokens + val_tokens + test_tokens for token in sentence)\n",
        "word_index = {word: i + 1 for i, word in enumerate(vocab)}\n",
        "\n",
        "embedding_dim = fasttext.dim\n",
        "embedding_matrix = np.zeros((len(word_index) + 1, embedding_dim))\n",
        "\n",
        "for word, i in word_index.items():\n",
        "    if word in fasttext.stoi:\n",
        "        embedding_matrix[i] = fasttext[word].numpy()"
      ],
      "metadata": {
        "id": "XBdjOnXZNqib"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_layer = Embedding(\n",
        "    input_dim=embedding_matrix.shape[0],\n",
        "    output_dim=embedding_dim,\n",
        "    weights=[embedding_matrix],\n",
        "    mask_zero=True,\n",
        "    trainable=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "iOA4grAPQk9z"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode as Bi-LSTM requires numbers to process\n",
        "def encode_sentences(token_lists, word_index, max_len):\n",
        "    sequences = [[word_index.get(token, 0) for token in tokens] for tokens in token_lists]\n",
        "    return pad_sequences(sequences, maxlen=max_len, padding=\"post\", truncating=\"post\")\n",
        "\n",
        "#using 90th percentile first\n",
        "max_len = 76\n",
        "\n",
        "X_train = encode_sentences(train_tokens, word_index, max_len)\n",
        "X_val = encode_sentences(val_tokens, word_index, max_len)\n",
        "X_test = encode_sentences(test_tokens, word_index, max_len)"
      ],
      "metadata": {
        "id": "uUrY8y_TRGG-"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_tags = df_train[\"ner_tags\"].tolist() + df_val[\"ner_tags\"].tolist() + df_test[\"ner_tags\"].tolist()\n",
        "\n",
        "tag_encoder = LabelEncoder()\n",
        "tag_encoder.fit([tag for seq in all_tags for tag in seq])\n",
        "num_classes = len(tag_encoder.classes_)\n",
        "\n",
        "def encode_tags(tag_lists, max_len):\n",
        "    encoded = [tag_encoder.transform(tags) for tags in tag_lists]\n",
        "    padded = pad_sequences(encoded, maxlen=max_len, padding=\"post\", truncating=\"post\", value=-1)  # -1 for masking\n",
        "    return padded\n",
        "\n",
        "y_train = encode_tags(df_train[\"ner_tags\"].tolist(), max_len)\n",
        "y_val = encode_tags(df_val[\"ner_tags\"].tolist(), max_len)\n",
        "y_test = encode_tags(df_test[\"ner_tags\"].tolist(), max_len)"
      ],
      "metadata": {
        "id": "QwbIHvKHRfx6"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = Input(shape=(max_len,))\n",
        "model = Embedding(input_dim=embedding_matrix.shape[0],\n",
        "                  output_dim=embedding_matrix.shape[1],\n",
        "                  weights=[embedding_matrix],\n",
        "                  input_length=max_len,\n",
        "                  mask_zero=True,\n",
        "                  trainable=True)(input)\n",
        "model = Bidirectional(LSTM(units=128, return_sequences=True))(model)\n",
        "model = Dense(num_classes, activation=\"softmax\")(model)\n",
        "\n",
        "model = Model(input, model)\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "zgdLcOTqSTcg",
        "outputId": "336f6409-eafd-4182-ffb5-a88bea9e1ca3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        }
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/Users/darren/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_4\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_4\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_4       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m76\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_8         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m76\u001b[0m, \u001b[38;5;34m300\u001b[0m)   │  \u001b[38;5;34m4,947,600\u001b[0m │ input_layer_4[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ not_equal_4         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m76\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ input_layer_4[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_4     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m76\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │    \u001b[38;5;34m439,296\u001b[0m │ embedding_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │ not_equal_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m76\u001b[0m, \u001b[38;5;34m4\u001b[0m)     │      \u001b[38;5;34m1,028\u001b[0m │ bidirectional_4[\u001b[38;5;34m…\u001b[0m │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_4       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">76</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_8         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">76</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">4,947,600</span> │ input_layer_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ not_equal_4         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">76</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_4     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">76</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">439,296</span> │ embedding_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │ not_equal_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">76</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,028</span> │ bidirectional_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,387,924\u001b[0m (20.55 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,387,924</span> (20.55 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,387,924\u001b[0m (20.55 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,387,924</span> (20.55 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_sample_weights(y_padded):\n",
        "    return (y_padded != -1).astype(\"float32\")\n",
        "\n",
        "sample_weights_train = create_sample_weights(y_train)\n",
        "sample_weights_val = create_sample_weights(y_val)\n",
        "\n",
        "y_train = np.where(y_train == -1, 0, y_train)\n",
        "y_val = np.where(y_val == -1, 0, y_val)\n",
        "\n"
      ],
      "metadata": {
        "id": "6ZYZOGfzWcgc"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training of model (using Adam as a baseline optimiser)\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.001),\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train[..., np.newaxis],\n",
        "    validation_data=(X_val, y_val[..., np.newaxis], sample_weights_val),\n",
        "    sample_weight=sample_weights_train,\n",
        "    batch_size=32,\n",
        "    epochs=15\n",
        ")\n"
      ],
      "metadata": {
        "id": "Gyqj5a5-Uc_y",
        "outputId": "2329c779-fd5d-46e1-9cd0-4d049f2fb0b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 97ms/step - accuracy: 0.3921 - loss: 0.7890 - val_accuracy: 0.4120 - val_loss: 0.4285\n",
            "Epoch 2/15\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 118ms/step - accuracy: 0.4391 - loss: 0.3382 - val_accuracy: 0.4313 - val_loss: 0.3501\n",
            "Epoch 3/15\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 148ms/step - accuracy: 0.4572 - loss: 0.2174 - val_accuracy: 0.4325 - val_loss: 0.3472\n",
            "Epoch 4/15\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 156ms/step - accuracy: 0.4802 - loss: 0.1362 - val_accuracy: 0.4350 - val_loss: 0.3588\n",
            "Epoch 5/15\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 152ms/step - accuracy: 0.4786 - loss: 0.0841 - val_accuracy: 0.4331 - val_loss: 0.3890\n",
            "Epoch 6/15\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 154ms/step - accuracy: 0.4922 - loss: 0.0516 - val_accuracy: 0.4295 - val_loss: 0.4305\n",
            "Epoch 7/15\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 153ms/step - accuracy: 0.5016 - loss: 0.0389 - val_accuracy: 0.4325 - val_loss: 0.4577\n",
            "Epoch 8/15\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 154ms/step - accuracy: 0.5042 - loss: 0.0213 - val_accuracy: 0.4317 - val_loss: 0.5061\n",
            "Epoch 9/15\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 155ms/step - accuracy: 0.5026 - loss: 0.0173 - val_accuracy: 0.4327 - val_loss: 0.5122\n",
            "Epoch 10/15\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 159ms/step - accuracy: 0.5034 - loss: 0.0109 - val_accuracy: 0.4296 - val_loss: 0.5600\n",
            "Epoch 11/15\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 163ms/step - accuracy: 0.4985 - loss: 0.0079 - val_accuracy: 0.4311 - val_loss: 0.5797\n",
            "Epoch 12/15\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 154ms/step - accuracy: 0.4987 - loss: 0.0055 - val_accuracy: 0.4282 - val_loss: 0.6025\n",
            "Epoch 13/15\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 161ms/step - accuracy: 0.4945 - loss: 0.0035 - val_accuracy: 0.4318 - val_loss: 0.6195\n",
            "Epoch 14/15\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 164ms/step - accuracy: 0.5019 - loss: 0.0028 - val_accuracy: 0.4288 - val_loss: 0.6471\n",
            "Epoch 15/15\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 162ms/step - accuracy: 0.5067 - loss: 0.0022 - val_accuracy: 0.4288 - val_loss: 0.6538\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_pred_labels = np.argmax(y_pred, axis=-1)\n",
        "\n",
        "idx2tag = {i: t for i, t in enumerate(tag_encoder.classes_)}\n",
        "\n",
        "true_labels = [[idx2tag[idx] for idx in row if idx != -1] for row in y_test]\n",
        "pred_labels = [[idx2tag[idx] for idx in row[:len(true_labels[i])]] for i, row in enumerate(y_pred_labels)]\n",
        "\n",
        "print(\"F1 Score:\", f1_score(true_labels, pred_labels))\n",
        "print(classification_report(true_labels, pred_labels))"
      ],
      "metadata": {
        "id": "Bxj2SSA8Sypt",
        "outputId": "2fa71c50-b90a-493f-da02-b8c97f7e45b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:5 out of the last 17 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x3267225c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "F1 Score: 0.6714570858283433\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          AC       0.77      0.79      0.78       741\n",
            "          LF       0.46      0.57      0.51       455\n",
            "\n",
            "   micro avg       0.64      0.70      0.67      1196\n",
            "   macro avg       0.62      0.68      0.65      1196\n",
            "weighted avg       0.66      0.70      0.68      1196\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mRLh79PeXcUU"
      },
      "execution_count": 31,
      "outputs": []
    }
  ]
}
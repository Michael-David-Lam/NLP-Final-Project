{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNJMXXlnYLxozP5DsKTR2f+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Michael-David-Lam/NLP-Final-Project/blob/main/Experiment_3_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Define General DistilBert Pipline"
      ],
      "metadata": {
        "id": "rdJm0lTtPK8i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install dependencies"
      ],
      "metadata": {
        "id": "oriwYxczN_Z-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "hUYndYu1wL9U",
        "outputId": "97400286-69e5-49f5-af58-4317108aaba1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.4.26)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.11/dist-packages (0.4.3)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.0.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.30.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (24.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.18.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.11.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.4.26)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "# Install dependencies\n",
        "!pip install torch torchvision\n",
        "!pip install transformers\n",
        "!pip install datasets\n",
        "!pip install evaluate\n",
        "# !pip install seqeval"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load packages and dataset"
      ],
      "metadata": {
        "id": "l86jimnWOGC8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load packages\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification, TrainingArguments, Trainer\n",
        "from datasets import load_dataset\n",
        "import evaluate"
      ],
      "metadata": {
        "id": "SdVAbb8iw6T2"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "dataset = load_dataset(\"surrey-nlp/PLOD-CW-25\")\n",
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5higd67F9xxH",
        "outputId": "579b827b-58e7-4b7a-dcaf-4a2d9ca33aeb"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['tokens', 'pos_tags', 'ner_tags'],\n",
              "        num_rows: 2000\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['tokens', 'pos_tags', 'ner_tags'],\n",
              "        num_rows: 250\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['tokens', 'pos_tags', 'ner_tags'],\n",
              "        num_rows: 150\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['train'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qeg3-Bzru8fY",
        "outputId": "4b40c581-ad58-45c8-dfcf-5878c09d78e6"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'tokens': ['MRR',\n",
              "  ',',\n",
              "  'mortality',\n",
              "  'rate',\n",
              "  'ratio',\n",
              "  ';',\n",
              "  'TBI',\n",
              "  ',',\n",
              "  'traumatic',\n",
              "  'brain',\n",
              "  'injury',\n",
              "  '.'],\n",
              " 'pos_tags': ['NOUN',\n",
              "  'PUNCT',\n",
              "  'NOUN',\n",
              "  'NOUN',\n",
              "  'NOUN',\n",
              "  'PUNCT',\n",
              "  'PROPN',\n",
              "  'PUNCT',\n",
              "  'ADJ',\n",
              "  'NOUN',\n",
              "  'NOUN',\n",
              "  'PUNCT'],\n",
              " 'ner_tags': ['B-AC',\n",
              "  'O',\n",
              "  'B-LF',\n",
              "  'I-LF',\n",
              "  'I-LF',\n",
              "  'O',\n",
              "  'B-AC',\n",
              "  'O',\n",
              "  'B-LF',\n",
              "  'I-LF',\n",
              "  'I-LF',\n",
              "  'O']}"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Model & Tokenizer\n",
        "### Tokenize data"
      ],
      "metadata": {
        "id": "dIRd1c-zOKMD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define model and tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")\n",
        "model = AutoModelForTokenClassification.from_pretrained(\n",
        "    \"distilbert-base-uncased\",\n",
        "    num_labels=4   # Class labels: B-AC, B-LF, I-LF, O\n",
        ")\n",
        "\n",
        "# this fucntion is to tokenize our dataset\n",
        "def tokenize_and_align_labels(batch):\n",
        "    tokenized = tokenizer(\n",
        "        batch[\"tokens\"],\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=128,\n",
        "        is_split_into_words=True\n",
        "    )\n",
        "\n",
        "    labels = batch[\"ner_tags\"]\n",
        "    label_to_id = {\"B-AC\": 0, \"B-LF\": 1, \"I-LF\": 2, \"O\": 3}\n",
        "    aligned_labels = []\n",
        "\n",
        "    for i, label in enumerate(labels):\n",
        "        word_ids = tokenized.word_ids(i)\n",
        "        aligned_label = []\n",
        "        for word_idx in word_ids:\n",
        "            if word_idx is None:\n",
        "                aligned_label.append(-100)  # for padding or special tokens\n",
        "            else:\n",
        "                aligned_label.append(label_to_id.get( label[min(word_idx, len(label) - 1)], -100 ))\n",
        "        aligned_labels.append(aligned_label)\n",
        "\n",
        "    tokenized[\"labels\"] = aligned_labels\n",
        "    return tokenized\n",
        "# create tokenized dataset\n",
        "tokenized_dataset = dataset.map(tokenize_and_align_labels, batched=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qj5oZC--LfIC",
        "outputId": "8dea6a5e-ed13-4ba8-9b5c-a511fb256232"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Define F1 Metric function"
      ],
      "metadata": {
        "id": "oEcaATRbOPGI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metric = evaluate.load(\"f1\")\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "\n",
        "    true_labels, true_preds = [], []\n",
        "    for pred_row, label_row in zip(preds, labels):\n",
        "        for p, l in zip(pred_row, label_row):\n",
        "            if l != -100:  # ignore padding\n",
        "                true_labels.append(l)\n",
        "                true_preds.append(p)\n",
        "\n",
        "    return metric.compute(predictions=true_preds, references=true_labels, average=\"weighted\")"
      ],
      "metadata": {
        "id": "vTV8HYVPYJu7"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Training Arguments"
      ],
      "metadata": {
        "id": "MEhxK_FSPAZ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define general training args\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    learning_rate=1e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=5,\n",
        "    weight_decay=0.01,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1\",\n",
        "    logging_strategy =\"epoch\",\n",
        "    report_to=\"none\",\n",
        ")"
      ],
      "metadata": {
        "id": "hrFTEJMLO_Cd"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Loss Function"
      ],
      "metadata": {
        "id": "rJSxbN_mP1MI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.nn import CrossEntropyLoss\n",
        "\n",
        "# Mannually define class weights\n",
        "# [B-AC, B-LF, I-LF, O]\n",
        "class_weights = torch.tensor([1.0, 2.0, 2.0, 0.5]).to(\"cuda\")\n",
        "\n",
        "# define custom trainer subclass to override loss default funtion\n",
        "class CustomTrainer(Trainer):\n",
        "    # Custom loss function - weighted CrossEntropyLoss\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
        "        # Forward pass\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        labels = inputs[\"labels\"]\n",
        "\n",
        "        # Flatten the logits and labels to match shape for CrossEntropyLoss\n",
        "        logits = logits.view(-1, model.config.num_labels)\n",
        "        labels = labels.view(-1)\n",
        "\n",
        "        # Apply CrossEntropyLoss with class weights\n",
        "        loss_fn = CrossEntropyLoss(weight=class_weights, ignore_index=-100)\n",
        "        loss = loss_fn(logits, labels)\n",
        "\n",
        "        if return_outputs:\n",
        "            return loss, outputs\n",
        "        else:\n",
        "            return loss"
      ],
      "metadata": {
        "id": "n8W21z0BP3qc"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiment Setup-1\n",
        "Optimizer = Adam"
      ],
      "metadata": {
        "id": "NTK-Wjh-N7is"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import Adam, AdamW\n",
        "\n",
        "# Define optimizers\n",
        "optimizer1 = Adam(model.parameters(), lr=1e-5)\n",
        "optimizer2 = AdamW(model.parameters(), lr=1e-5)"
      ],
      "metadata": {
        "id": "xdIExrGETl_K"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Default Trainer Class:\n",
        " * Loss Function - Cross Entropy Loss\n",
        " * Optimizer - Adam"
      ],
      "metadata": {
        "id": "o9Ps8C6YaDUl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Init default trainer - Cross Entropy loss, Adam Optimizer\n",
        "trainer1_cross = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset[\"train\"],\n",
        "    eval_dataset=tokenized_dataset[\"validation\"],\n",
        "    compute_metrics=compute_metrics,\n",
        "    optimizers=(optimizer1, None) #custom optimizer\n",
        ")\n",
        "trainer1_cross.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "CdmHPqSTUW83",
        "outputId": "f4c93bad-dac5-4d48-9329-c1092b336bbb"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1250' max='1250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1250/1250 02:28, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.504000</td>\n",
              "      <td>0.355043</td>\n",
              "      <td>0.875538</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.292000</td>\n",
              "      <td>0.353592</td>\n",
              "      <td>0.880516</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.251300</td>\n",
              "      <td>0.337270</td>\n",
              "      <td>0.882887</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.227400</td>\n",
              "      <td>0.338602</td>\n",
              "      <td>0.885893</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.215000</td>\n",
              "      <td>0.339942</td>\n",
              "      <td>0.886398</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1250, training_loss=0.29795047912597655, metrics={'train_runtime': 148.6217, 'train_samples_per_second': 67.285, 'train_steps_per_second': 8.411, 'total_flos': 326644561920000.0, 'train_loss': 0.29795047912597655, 'epoch': 5.0})"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer1_cross.evaluate(eval_dataset=tokenized_dataset[\"test\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "KCcXtsLYeWnm",
        "outputId": "4328cc41-fe56-4268-d562-2c5f55af2093"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [32/32 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 0.2549479603767395,\n",
              " 'eval_f1': 0.9076819111211382,\n",
              " 'eval_runtime': 1.0305,\n",
              " 'eval_samples_per_second': 242.602,\n",
              " 'eval_steps_per_second': 31.053,\n",
              " 'epoch': 5.0}"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Custom Trainer Class:\n",
        "  * Loss Function - Weighted Cross Entropy Loss\n",
        "  * Optimizer - Adam"
      ],
      "metadata": {
        "id": "fGxsiyUxaOxO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Init custom trainer - Weighted Cross Entropy loss, Adam Optimizer\n",
        "trainer1_crossW = CustomTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset[\"train\"],\n",
        "    eval_dataset=tokenized_dataset[\"validation\"],\n",
        "    compute_metrics=compute_metrics,\n",
        "    optimizers=(optimizer1, None) #custom optimizer\n",
        ")\n",
        "trainer1_crossW.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "zGYQ3NMfk0WH",
        "outputId": "418eb177-d287-455c-8957-527477ecbeeb"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1250' max='1250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1250/1250 02:28, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.233500</td>\n",
              "      <td>0.415790</td>\n",
              "      <td>0.887523</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.187800</td>\n",
              "      <td>0.435304</td>\n",
              "      <td>0.885267</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.163200</td>\n",
              "      <td>0.477409</td>\n",
              "      <td>0.888828</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.147700</td>\n",
              "      <td>0.463142</td>\n",
              "      <td>0.886348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.141100</td>\n",
              "      <td>0.470170</td>\n",
              "      <td>0.887665</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1250, training_loss=0.17465748291015626, metrics={'train_runtime': 148.4646, 'train_samples_per_second': 67.356, 'train_steps_per_second': 8.42, 'total_flos': 326644561920000.0, 'train_loss': 0.17465748291015626, 'epoch': 5.0})"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer1_crossW.evaluate(eval_dataset=tokenized_dataset[\"test\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "1TcTUXpqegit",
        "outputId": "15d03c7d-ab45-4b22-be6b-8541e9563dd8"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [32/32 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 0.3371643126010895,\n",
              " 'eval_f1': 0.9076053030230822,\n",
              " 'eval_runtime': 1.1806,\n",
              " 'eval_samples_per_second': 211.762,\n",
              " 'eval_steps_per_second': 27.106,\n",
              " 'epoch': 5.0}"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiment Setup-2\n",
        "Optimizer = AdamW"
      ],
      "metadata": {
        "id": "FRN1UutIN14p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Default Trainer Class:\n",
        "  * Loss Function - Cross Entropy Loss\n",
        "  * Optimizer - AdamW"
      ],
      "metadata": {
        "id": "BVvSiWJAaSYe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Init second default trainer - Cross Entropy loss, AdamW Optimizer\n",
        "trainer2_cross = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset[\"train\"],\n",
        "    eval_dataset=tokenized_dataset[\"validation\"],\n",
        "    compute_metrics=compute_metrics,\n",
        "    optimizers=(optimizer2, None) #custom optimizer\n",
        ")\n",
        "trainer2_cross.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "KeonzGwuUfcQ",
        "outputId": "47915071-1332-4fa2-8374-264cb7c1169e"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1250' max='1250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1250/1250 02:34, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.138700</td>\n",
              "      <td>0.428351</td>\n",
              "      <td>0.886464</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.113600</td>\n",
              "      <td>0.469192</td>\n",
              "      <td>0.885303</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.100900</td>\n",
              "      <td>0.453622</td>\n",
              "      <td>0.882394</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.097900</td>\n",
              "      <td>0.457666</td>\n",
              "      <td>0.886917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.092500</td>\n",
              "      <td>0.463837</td>\n",
              "      <td>0.884596</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1250, training_loss=0.10869351501464844, metrics={'train_runtime': 154.5043, 'train_samples_per_second': 64.723, 'train_steps_per_second': 8.09, 'total_flos': 326644561920000.0, 'train_loss': 0.10869351501464844, 'epoch': 5.0})"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer2_cross.evaluate(eval_dataset=tokenized_dataset[\"test\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "td7fpQNEeiG7",
        "outputId": "3d3ddfb5-f8e3-4448-f104-64de4a126863"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [32/32 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 0.31509044766426086,\n",
              " 'eval_f1': 0.9048358952897892,\n",
              " 'eval_runtime': 1.0179,\n",
              " 'eval_samples_per_second': 245.608,\n",
              " 'eval_steps_per_second': 31.438,\n",
              " 'epoch': 5.0}"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Custom Trainer Class:\n",
        "  * Loss Function - Weighted Cross Entropy Loss\n",
        "  * Optimizer - AdamW"
      ],
      "metadata": {
        "id": "FDSiu5WfaTrW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Init second custom trainer - Weighted Cross Entropy loss, AdamW Optimizer\n",
        "trainer2_crossW = CustomTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset[\"train\"],\n",
        "    eval_dataset=tokenized_dataset[\"validation\"],\n",
        "    compute_metrics=compute_metrics,\n",
        "    optimizers=(optimizer2, None) #custom optimizer\n",
        ")\n",
        "trainer2_crossW.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "qLkOuITINlyV",
        "outputId": "f91d7ae5-d4ba-495e-a4a1-553d471043ff"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1250' max='1250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1250/1250 02:33, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.073400</td>\n",
              "      <td>0.657009</td>\n",
              "      <td>0.885023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.057700</td>\n",
              "      <td>0.662524</td>\n",
              "      <td>0.886114</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.050900</td>\n",
              "      <td>0.703807</td>\n",
              "      <td>0.885237</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.053000</td>\n",
              "      <td>0.689678</td>\n",
              "      <td>0.884397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.061600</td>\n",
              "      <td>0.676018</td>\n",
              "      <td>0.884780</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1250, training_loss=0.059328802490234374, metrics={'train_runtime': 153.1119, 'train_samples_per_second': 65.312, 'train_steps_per_second': 8.164, 'total_flos': 326644561920000.0, 'train_loss': 0.059328802490234374, 'epoch': 5.0})"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer2_crossW.evaluate(eval_dataset=tokenized_dataset[\"test\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "SqD2Sg5uejeS",
        "outputId": "f5628206-f213-4b23-89ad-a8b0574589bf"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [32/32 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 0.4350109398365021,\n",
              " 'eval_f1': 0.910539946631976,\n",
              " 'eval_runtime': 1.0774,\n",
              " 'eval_samples_per_second': 232.05,\n",
              " 'eval_steps_per_second': 29.702,\n",
              " 'epoch': 5.0}"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Visualization"
      ],
      "metadata": {
        "id": "vN_VQaznZDQM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#add code"
      ],
      "metadata": {
        "id": "2yDkgqmvZFEh"
      },
      "execution_count": 61,
      "outputs": []
    }
  ]
}
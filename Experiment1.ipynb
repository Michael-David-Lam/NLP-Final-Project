{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Michael-David-Lam/NLP-Final-Project/blob/main/Experiment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "jWKCC-_gXWtc"
      },
      "outputs": [],
      "source": [
        "# !pip install datasets\n",
        "# !pip install gensim\n",
        "# !pip install --upgrade numpy gensim\n",
        "# !pip install tensorflow\n",
        "# !pip install seqeval\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "from gensim.models import Word2Vec\n",
        "import ast"
      ],
      "metadata": {
        "id": "06GTRetkG1bS"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"surrey-nlp/PLOD-CW-25\")\n",
        "\n",
        "print(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUG9YpxlDAIJ",
        "outputId": "f46e9ce8-21c5-468e-f7a6-5baafb4d6ec1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['tokens', 'pos_tags', 'ner_tags'],\n",
            "        num_rows: 2000\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['tokens', 'pos_tags', 'ner_tags'],\n",
            "        num_rows: 250\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['tokens', 'pos_tags', 'ner_tags'],\n",
            "        num_rows: 150\n",
            "    })\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.DataFrame(dataset[\"train\"])\n",
        "df_val = pd.DataFrame(dataset[\"validation\"])\n",
        "df_test = pd.DataFrame(dataset[\"test\"])"
      ],
      "metadata": {
        "id": "PvGTSh7QGtXH"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#To combine train,test,split for vectorisation to build a rich embedding space\n",
        "\n",
        "import ast\n",
        "\n",
        "def safe_parse(col):\n",
        "    return [ast.literal_eval(row) if isinstance(row, str) else row for row in col]\n",
        "\n",
        "train_tokens = safe_parse(df_train[\"tokens\"])\n",
        "val_tokens = safe_parse(df_val[\"tokens\"])\n",
        "test_tokens = safe_parse(df_test[\"tokens\"])\n",
        "\n",
        "all_tokens = train_tokens + val_tokens + test_tokens"
      ],
      "metadata": {
        "id": "bWoGJ6j2Ngdh"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(df_train['tokens'][0])"
      ],
      "metadata": {
        "id": "y1XH0OrgG-wS",
        "outputId": "c45981a4-6578-4c50-8f73-db62ebc2ec58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#List of Parameters (Just using Lab as reference)\n",
        "num_features = 300\n",
        "min_word_count = 1\n",
        "num_workers = 2\n",
        "window_size = 3\n",
        "subsampling = 1e-3"
      ],
      "metadata": {
        "id": "UKaTDzcpIF8U"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model = Word2Vec(\n",
        "    sentences=all_tokens,\n",
        "    vector_size=num_features,\n",
        "    window=window_size,\n",
        "    min_count=min_word_count,\n",
        "    workers=num_workers,\n",
        "    sample=subsampling\n",
        ")"
      ],
      "metadata": {
        "id": "Z7G0bl6CNUkP"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preparation of data (Creating vocab + embeding matrix from model itself)"
      ],
      "metadata": {
        "id": "SHmO8pSxQoOB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import KeyedVectors\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "vocab = w2v_model.wv.index_to_key\n",
        "word_index = {word: idx + 1 for idx, word in enumerate(vocab)}\n",
        "\n",
        "embedding_dim = w2v_model.vector_size\n",
        "embedding_matrix = np.zeros((len(word_index) + 1, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    embedding_matrix[i] = w2v_model.wv[word]\n"
      ],
      "metadata": {
        "id": "XBdjOnXZNqib"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_lengths = [len(seq) for seq in train_tokens + val_tokens + test_tokens]\n",
        "\n",
        "print(max(all_lengths))\n",
        "print(np.mean(all_lengths))\n",
        "print(np.percentile(all_lengths, 90))\n",
        "#likelihood to chose 76 to get the best balance of computational power + covers 90% of sequence"
      ],
      "metadata": {
        "id": "iOA4grAPQk9z",
        "outputId": "73618f69-84dd-44eb-e7bb-9fc1ff2b22ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "371\n",
            "41.17041666666667\n",
            "76.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode as Bi-LSTM requires numbers to process\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "def encode_sentences(token_lists, word_index, max_len):\n",
        "    sequences = [[word_index.get(token, 0) for token in tokens] for tokens in token_lists]\n",
        "    return pad_sequences(sequences, maxlen=max_len, padding=\"post\", truncating=\"post\")\n",
        "\n",
        "#using 90th percentile first\n",
        "max_len = 76\n",
        "\n",
        "X_train = encode_sentences(train_tokens, word_index, max_len)\n",
        "X_val = encode_sentences(val_tokens, word_index, max_len)\n",
        "X_test = encode_sentences(test_tokens, word_index, max_len)"
      ],
      "metadata": {
        "id": "uUrY8y_TRGG-"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "all_tags = df_train[\"ner_tags\"].tolist() + df_val[\"ner_tags\"].tolist() + df_test[\"ner_tags\"].tolist()\n",
        "\n",
        "tag_encoder = LabelEncoder()\n",
        "tag_encoder.fit([tag for seq in all_tags for tag in seq])\n",
        "num_classes = len(tag_encoder.classes_)\n",
        "\n",
        "def encode_tags(tag_lists, max_len):\n",
        "    encoded = [tag_encoder.transform(tags) for tags in tag_lists]\n",
        "    padded = pad_sequences(encoded, maxlen=max_len, padding=\"post\", truncating=\"post\", value=-1)  # -1 for masking\n",
        "    return padded\n",
        "\n",
        "y_train = encode_tags(df_train[\"ner_tags\"].tolist(), max_len)\n",
        "y_val = encode_tags(df_val[\"ner_tags\"].tolist(), max_len)\n",
        "y_test = encode_tags(df_test[\"ner_tags\"].tolist(), max_len)\n"
      ],
      "metadata": {
        "id": "QwbIHvKHRfx6"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, Bidirectional, LSTM, TimeDistributed, Dense, Masking\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "input = Input(shape=(max_len,))\n",
        "model = Embedding(input_dim=embedding_matrix.shape[0],\n",
        "                  output_dim=embedding_matrix.shape[1],\n",
        "                  weights=[embedding_matrix],\n",
        "                  input_length=max_len,\n",
        "                  mask_zero=True,\n",
        "                  trainable=True)(input)\n",
        "model = Bidirectional(LSTM(units=128, return_sequences=True))(model)\n",
        "model = Dense(num_classes, activation=\"softmax\")(model)\n",
        "\n",
        "model = Model(input, model)\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "zgdLcOTqSTcg",
        "outputId": "14374f63-5f6a-4629-e4df-6bf1794b2503",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m76\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m76\u001b[0m, \u001b[38;5;34m300\u001b[0m)        │      \u001b[38;5;34m4,947,600\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ not_equal_1 (\u001b[38;5;33mNotEqual\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m76\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ bidirectional_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m76\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │        \u001b[38;5;34m439,296\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)           │                        │                │ not_equal_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m76\u001b[0m, \u001b[38;5;34m4\u001b[0m)          │          \u001b[38;5;34m1,028\u001b[0m │ bidirectional_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">76</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">76</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,947,600</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ not_equal_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">76</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ bidirectional_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">76</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">439,296</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)           │                        │                │ not_equal_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">76</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,028</span> │ bidirectional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,387,924\u001b[0m (20.55 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,387,924</span> (20.55 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,387,924\u001b[0m (20.55 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,387,924</span> (20.55 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_sample_weights(y_padded):\n",
        "    return (y_padded != -1).astype(\"float32\")\n",
        "\n",
        "sample_weights_train = create_sample_weights(y_train)\n",
        "sample_weights_val = create_sample_weights(y_val)\n",
        "\n",
        "y_train = np.where(y_train == -1, 0, y_train)\n",
        "y_val = np.where(y_val == -1, 0, y_val)\n",
        "\n"
      ],
      "metadata": {
        "id": "6ZYZOGfzWcgc"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training of model (using Adam as a baseline optimiser)\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.001),\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train[..., np.newaxis],\n",
        "    validation_data=(X_val, y_val[..., np.newaxis], sample_weights_val),\n",
        "    sample_weight=sample_weights_train,\n",
        "    batch_size=32,\n",
        "    epochs=15\n",
        ")\n"
      ],
      "metadata": {
        "id": "Gyqj5a5-Uc_y",
        "outputId": "9adca4d6-7712-48bd-d621-189b81a091cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 456ms/step - accuracy: 0.3904 - loss: 0.8014 - val_accuracy: 0.4018 - val_loss: 0.5164\n",
            "Epoch 2/15\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 452ms/step - accuracy: 0.4215 - loss: 0.4255 - val_accuracy: 0.4282 - val_loss: 0.3796\n",
            "Epoch 3/15\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 437ms/step - accuracy: 0.4513 - loss: 0.2592 - val_accuracy: 0.4285 - val_loss: 0.3699\n",
            "Epoch 4/15\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 448ms/step - accuracy: 0.4799 - loss: 0.1650 - val_accuracy: 0.4326 - val_loss: 0.3726\n",
            "Epoch 5/15\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 435ms/step - accuracy: 0.4887 - loss: 0.0960 - val_accuracy: 0.4303 - val_loss: 0.3957\n",
            "Epoch 6/15\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 453ms/step - accuracy: 0.4963 - loss: 0.0608 - val_accuracy: 0.4325 - val_loss: 0.4243\n",
            "Epoch 7/15\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 457ms/step - accuracy: 0.4918 - loss: 0.0399 - val_accuracy: 0.4311 - val_loss: 0.4668\n",
            "Epoch 8/15\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 447ms/step - accuracy: 0.4974 - loss: 0.0306 - val_accuracy: 0.4269 - val_loss: 0.5154\n",
            "Epoch 9/15\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 450ms/step - accuracy: 0.4938 - loss: 0.0221 - val_accuracy: 0.4304 - val_loss: 0.5259\n",
            "Epoch 10/15\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 438ms/step - accuracy: 0.4981 - loss: 0.0157 - val_accuracy: 0.4292 - val_loss: 0.5571\n",
            "Epoch 11/15\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 421ms/step - accuracy: 0.4985 - loss: 0.0106 - val_accuracy: 0.4273 - val_loss: 0.5853\n",
            "Epoch 12/15\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 437ms/step - accuracy: 0.5053 - loss: 0.0089 - val_accuracy: 0.4277 - val_loss: 0.6028\n",
            "Epoch 13/15\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 449ms/step - accuracy: 0.4930 - loss: 0.0053 - val_accuracy: 0.4281 - val_loss: 0.6311\n",
            "Epoch 14/15\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 436ms/step - accuracy: 0.5112 - loss: 0.0041 - val_accuracy: 0.4252 - val_loss: 0.6554\n",
            "Epoch 15/15\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 499ms/step - accuracy: 0.5006 - loss: 0.0042 - val_accuracy: 0.4268 - val_loss: 0.6769\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from seqeval.metrics import classification_report, f1_score\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_labels = np.argmax(y_pred, axis=-1)\n",
        "\n",
        "idx2tag = {i: t for i, t in enumerate(tag_encoder.classes_)}\n",
        "\n",
        "true_labels = [[idx2tag[idx] for idx in row if idx != -1] for row in y_test]\n",
        "pred_labels = [[idx2tag[idx] for idx in row[:len(true_labels[i])]] for i, row in enumerate(y_pred_labels)]\n",
        "\n",
        "print(\"F1 Score:\", f1_score(true_labels, pred_labels))\n",
        "# print(classification_report(true_labels, pred_labels))"
      ],
      "metadata": {
        "id": "Bxj2SSA8Sypt",
        "outputId": "4f68c095-ebaa-468a-b864-2b5c8ed1d3c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 259ms/step\n",
            "F1 Score: 0.6530944625407165\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mRLh79PeXcUU"
      },
      "execution_count": 31,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Michael-David-Lam/NLP-Final-Project/blob/main/Experiment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "jWKCC-_gXWtc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35ba415a-28e9-4122-c8f5-ab031fdfd028"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/43.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from seqeval) (1.26.4)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.11/dist-packages (from seqeval) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.6.0)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16161 sha256=92176fce99b385a244f099aed212f04d3750e7a80303b79d9448ef202ad4b761\n",
            "  Stored in directory: /root/.cache/pip/wheels/bc/92/f0/243288f899c2eacdfa8c5f9aede4c71a9bad0ee26a01dc5ead\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-1.2.2\n"
          ]
        }
      ],
      "source": [
        "# !pip install datasets\n",
        "# !pip install gensim\n",
        "# !pip install --upgrade numpy gensim\n",
        "# !pip install tensorflow\n",
        "# !pip install seqeval\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "from gensim.models import Word2Vec\n",
        "import ast"
      ],
      "metadata": {
        "id": "06GTRetkG1bS"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"surrey-nlp/PLOD-CW-25\")\n",
        "\n",
        "print(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUG9YpxlDAIJ",
        "outputId": "46efbab5-e2c3-40c2-d58a-9ed284ecf7b4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['tokens', 'pos_tags', 'ner_tags'],\n",
            "        num_rows: 2000\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['tokens', 'pos_tags', 'ner_tags'],\n",
            "        num_rows: 250\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['tokens', 'pos_tags', 'ner_tags'],\n",
            "        num_rows: 150\n",
            "    })\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.DataFrame(dataset[\"train\"])\n",
        "df_val = pd.DataFrame(dataset[\"validation\"])\n",
        "df_test = pd.DataFrame(dataset[\"test\"])"
      ],
      "metadata": {
        "id": "PvGTSh7QGtXH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#To combine train,test,split for vectorisation to build a rich embedding space\n",
        "\n",
        "import ast\n",
        "\n",
        "def safe_parse(col):\n",
        "    return [ast.literal_eval(row) if isinstance(row, str) else row for row in col]\n",
        "\n",
        "train_tokens = safe_parse(df_train[\"tokens\"])\n",
        "val_tokens = safe_parse(df_val[\"tokens\"])\n",
        "test_tokens = safe_parse(df_test[\"tokens\"])\n",
        "\n",
        "all_tokens = train_tokens + val_tokens + test_tokens"
      ],
      "metadata": {
        "id": "bWoGJ6j2Ngdh"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(df_train['tokens'][0])"
      ],
      "metadata": {
        "id": "y1XH0OrgG-wS",
        "outputId": "b75af5e6-a71e-4475-ac9f-944a6136f084",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#List of Parameters (Just using Lab as reference)\n",
        "num_features = 300\n",
        "min_word_count = 1\n",
        "num_workers = 2\n",
        "window_size = 3\n",
        "subsampling = 1e-3"
      ],
      "metadata": {
        "id": "UKaTDzcpIF8U"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model = Word2Vec(\n",
        "    sentences=all_tokens,\n",
        "    vector_size=num_features,\n",
        "    window=window_size,\n",
        "    min_count=min_word_count,\n",
        "    workers=num_workers,\n",
        "    sample=subsampling\n",
        ")"
      ],
      "metadata": {
        "id": "Z7G0bl6CNUkP"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preparation of data (Creating vocab + embeding matrix from model itself)"
      ],
      "metadata": {
        "id": "SHmO8pSxQoOB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import KeyedVectors\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "vocab = w2v_model.wv.index_to_key\n",
        "word_index = {word: idx + 1 for idx, word in enumerate(vocab)}\n",
        "\n",
        "embedding_dim = w2v_model.vector_size\n",
        "embedding_matrix = np.zeros((len(word_index) + 1, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    embedding_matrix[i] = w2v_model.wv[word]\n"
      ],
      "metadata": {
        "id": "XBdjOnXZNqib"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_lengths = [len(seq) for seq in train_tokens + val_tokens + test_tokens]\n",
        "\n",
        "print(max(all_lengths))\n",
        "print(np.mean(all_lengths))\n",
        "print(np.percentile(all_lengths, 90))\n",
        "#likelihood to chose 76 to get the best balance of computational power + covers 90% of sequence"
      ],
      "metadata": {
        "id": "iOA4grAPQk9z",
        "outputId": "e36bfc5d-1fd4-463e-a6b8-3c6bb9de271e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "371\n",
            "41.17041666666667\n",
            "76.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "def encode_sentences(token_lists, word_index, max_len):\n",
        "    sequences = [[word_index.get(token, 0) for token in tokens] for tokens in token_lists]\n",
        "    return pad_sequences(sequences, maxlen=max_len, padding=\"post\", truncating=\"post\")\n",
        "\n",
        "#using 90th percentile first\n",
        "max_len = 76\n",
        "\n",
        "X_train = encode_sentences(train_tokens, word_index, max_len)\n",
        "X_val = encode_sentences(val_tokens, word_index, max_len)\n",
        "X_test = encode_sentences(test_tokens, word_index, max_len)"
      ],
      "metadata": {
        "id": "uUrY8y_TRGG-"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "all_tags = df_train[\"ner_tags\"].tolist() + df_val[\"ner_tags\"].tolist() + df_test[\"ner_tags\"].tolist()\n",
        "\n",
        "tag_encoder = LabelEncoder()\n",
        "tag_encoder.fit([tag for seq in all_tags for tag in seq])\n",
        "num_classes = len(tag_encoder.classes_)\n",
        "\n",
        "def encode_tags(tag_lists, max_len):\n",
        "    encoded = [tag_encoder.transform(tags) for tags in tag_lists]\n",
        "    padded = pad_sequences(encoded, maxlen=max_len, padding=\"post\", truncating=\"post\", value=-1)  # -1 for masking\n",
        "    return padded\n",
        "\n",
        "y_train = encode_tags(df_train[\"ner_tags\"].tolist(), max_len)\n",
        "y_val = encode_tags(df_val[\"ner_tags\"].tolist(), max_len)\n",
        "y_test = encode_tags(df_test[\"ner_tags\"].tolist(), max_len)\n"
      ],
      "metadata": {
        "id": "QwbIHvKHRfx6"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, Bidirectional, LSTM, TimeDistributed, Dense, Masking\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "input = Input(shape=(max_len,))\n",
        "model = Embedding(input_dim=embedding_matrix.shape[0],\n",
        "                  output_dim=embedding_matrix.shape[1],\n",
        "                  weights=[embedding_matrix],\n",
        "                  input_length=max_len,\n",
        "                  mask_zero=True,\n",
        "                  trainable=False)(input)\n",
        "model = Bidirectional(LSTM(units=64, return_sequences=True))(model)\n",
        "model = Dense(num_classes, activation=\"softmax\")(model)\n",
        "\n",
        "model = Model(input, model)\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "zgdLcOTqSTcg",
        "outputId": "44a3ce9c-49ef-4766-f788-619dff31a175",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m76\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m76\u001b[0m, \u001b[38;5;34m300\u001b[0m)        │      \u001b[38;5;34m4,947,600\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ not_equal_1 (\u001b[38;5;33mNotEqual\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m76\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ bidirectional_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m76\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m186,880\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)           │                        │                │ not_equal_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m76\u001b[0m, \u001b[38;5;34m4\u001b[0m)          │            \u001b[38;5;34m516\u001b[0m │ bidirectional_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">76</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">76</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,947,600</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ not_equal_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">76</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ bidirectional_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">76</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">186,880</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)           │                        │                │ not_equal_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">76</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)          │            <span style=\"color: #00af00; text-decoration-color: #00af00\">516</span> │ bidirectional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,134,996\u001b[0m (19.59 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,134,996</span> (19.59 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m187,396\u001b[0m (732.02 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">187,396</span> (732.02 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m4,947,600\u001b[0m (18.87 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,947,600</span> (18.87 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_sample_weights(y_padded):\n",
        "    return (y_padded != -1).astype(\"float32\")\n",
        "\n",
        "sample_weights_train = create_sample_weights(y_train)\n",
        "sample_weights_val = create_sample_weights(y_val)\n",
        "\n",
        "y_train = np.where(y_train == -1, 0, y_train)\n",
        "y_val = np.where(y_val == -1, 0, y_val)\n",
        "\n"
      ],
      "metadata": {
        "id": "6ZYZOGfzWcgc"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training of model (using Adam as a baseline optimiser)\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.001),\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train[..., np.newaxis],\n",
        "    validation_data=(X_val, y_val[..., np.newaxis], sample_weights_val),\n",
        "    sample_weight=sample_weights_train,\n",
        "    batch_size=32,\n",
        "    epochs=5\n",
        ")\n"
      ],
      "metadata": {
        "id": "Gyqj5a5-Uc_y",
        "outputId": "dac3173d-c3c9-47d9-ff2e-62e88a6ce0ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 167ms/step - accuracy: 0.3978 - loss: 0.8395 - val_accuracy: 0.3660 - val_loss: 0.7195\n",
            "Epoch 2/5\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 136ms/step - accuracy: 0.3745 - loss: 0.6952 - val_accuracy: 0.3695 - val_loss: 0.6527\n",
            "Epoch 3/5\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 175ms/step - accuracy: 0.3893 - loss: 0.6163 - val_accuracy: 0.3951 - val_loss: 0.5741\n",
            "Epoch 4/5\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 158ms/step - accuracy: 0.3967 - loss: 0.5786 - val_accuracy: 0.3920 - val_loss: 0.5463\n",
            "Epoch 5/5\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 198ms/step - accuracy: 0.4047 - loss: 0.5410 - val_accuracy: 0.3979 - val_loss: 0.5341\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from seqeval.metrics import classification_report, f1_score\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_labels = np.argmax(y_pred, axis=-1)\n",
        "\n",
        "idx2tag = {i: t for i, t in enumerate(tag_encoder.classes_)}\n",
        "\n",
        "true_labels = [[idx2tag[idx] for idx in row if idx != -1] for row in y_test]\n",
        "pred_labels = [[idx2tag[idx] for idx in row[:len(true_labels[i])]] for i, row in enumerate(y_pred_labels)]\n",
        "\n",
        "print(\"F1 Score:\", f1_score(true_labels, pred_labels))\n",
        "# print(classification_report(true_labels, pred_labels))"
      ],
      "metadata": {
        "id": "Bxj2SSA8Sypt",
        "outputId": "eb169136-3b79-45b7-b864-4a9e08a938f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step\n",
            "F1 Score: 0.486714466469844\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mRLh79PeXcUU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}